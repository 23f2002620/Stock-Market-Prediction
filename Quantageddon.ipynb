{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbGmH9ljkO6gKf+t8n5P3Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saravanan-039/Stock-Market-Prediction/blob/main/Quantageddon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Linear-Regression\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "features = ['High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
        "X_train = train_data[features]\n",
        "y_train = train_data['Open']\n",
        "X_test = test_data[features]\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "test_data['Open'] = model.predict(X_test)\n",
        "output = test_data[['id', 'Open']]\n",
        "output.to_csv('submission.csv', index=False)\n",
        "print(\"Submission file created: submission.csv\")\n",
        "rmse = mean_squared_error(y_train, train_predictions)\n",
        "r2 = r2_score(y_train, train_predictions)\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"R²: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWFkY9QC4DSj",
        "outputId": "3ddf6969-ff2a-41db-d3ac-5af782769fbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created: submission.csv\n",
            "RMSE: 1478.084567876389\n",
            "R²: 0.9998610928181338\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Random-Forest\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "features = ['High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
        "X_train = train_data[features]\n",
        "y_train = train_data['Open']\n",
        "X_test = test_data[features]\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "train_predictions = model.predict(X_train)\n",
        "test_data['Open'] = model.predict(X_test)\n",
        "output = test_data[['id', 'Open']]\n",
        "output.to_csv('submission1.csv', index=False)\n",
        "print(\"Submission file created: submission.csv\")\n",
        "rmse = mean_squared_error(y_train, train_predictions)\n",
        "r2 = r2_score(y_train, train_predictions)\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"R²: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHFjGZUhKg9j",
        "outputId": "1e3a1e99-d570-4a29-8abc-e205c5063dd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created: submission.csv\n",
            "RMSE: 556.9270541481595\n",
            "R²: 0.9999476612033722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBoost\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import xgboost as xgb\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "features = ['High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
        "X_train = train_data[features]\n",
        "y_train = train_data['Open']\n",
        "X_test = test_data[features]\n",
        "model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "train_predictions = model.predict(X_train)\n",
        "test_data['Open'] = model.predict(X_test)\n",
        "output = test_data[['id', 'Open']]\n",
        "output.to_csv('submission_xgboost.csv', index=False)\n",
        "print(\"Submission file created: submission_xgboost.csv\")\n",
        "rmse = mean_squared_error(y_train, train_predictions)\n",
        "r2 = r2_score(y_train, train_predictions)\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"R²: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoM4PetiL0i9",
        "outputId": "25c7c93f-ef1e-4ddf-a3da-0465b8aa4f3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created: submission_xgboost.csv\n",
            "RMSE: 540.3718303893883\n",
            "R²: 0.9999492170273944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LightGBM\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import lightgbm as lgb\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "features = ['High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
        "X_train = train_data[features]\n",
        "y_train = train_data['Open']\n",
        "X_test = test_data[features]\n",
        "model = lgb.LGBMRegressor(objective='regression', random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "train_predictions = model.predict(X_train)\n",
        "test_data['Open'] = model.predict(X_test)\n",
        "output = test_data[['id', 'Open']]\n",
        "output.to_csv('submission_lightgbm.csv', index=False)\n",
        "print(\"Submission file created: submission_lightgbm.csv\")\n",
        "rmse = mean_squared_error(y_train, train_predictions)\n",
        "r2 = r2_score(y_train, train_predictions)\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"R²: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_W3-r9mMcOt",
        "outputId": "4cffbd05-0de3-4221-fc5b-86bc8bc4846d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1020\n",
            "[LightGBM] [Info] Number of data points in the train set: 1968, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 11581.228052\n",
            "Submission file created: submission_lightgbm.csv\n",
            "RMSE: 1717.1432856802248\n",
            "R²: 0.99983862659833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision tree\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "features = ['High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
        "X_train = train_data[features]\n",
        "y_train = train_data['Open']\n",
        "X_test = test_data[features]\n",
        "model = DecisionTreeRegressor(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "train_predictions = model.predict(X_train)\n",
        "test_data['Open'] = model.predict(X_test)\n",
        "output = test_data[['id', 'Open']]\n",
        "output.to_csv('submission_decision_tree.csv', index=False)\n",
        "print(\"Submission file created: submission_decision_tree.csv\")\n",
        "rmse = mean_squared_error(y_train, train_predictions)\n",
        "r2 = r2_score(y_train, train_predictions)\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"R²: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Vq1iX_RcYxi",
        "outputId": "a9be04f4-965f-4f62-9500-aa2858455134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created: submission_decision_tree.csv\n",
            "RMSE: 0.0\n",
            "R²: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM algorithm\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "features = ['High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
        "X_train = train_data[features]\n",
        "y_train = train_data['Open']\n",
        "X_test = test_data[features]\n",
        "model = SVR()\n",
        "model.fit(X_train, y_train)\n",
        "train_predictions = model.predict(X_train)\n",
        "test_data['Open'] = model.predict(X_test)\n",
        "output = test_data[['id', 'Open']]\n",
        "output.to_csv('submission_svm.csv', index=False)\n",
        "print(\"Submission file created: submission_svm.csv\")\n",
        "rmse = mean_squared_error(y_train, train_predictions)\n",
        "r2 = r2_score(y_train, train_predictions)\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"R²: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyOiANF-c9bQ",
        "outputId": "16f7da35-31f9-49b1-8514-892081a9a1c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created: submission_svm.csv\n",
            "RMSE: 11005542.231182069\n",
            "R²: -0.03427698892655373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Linear-Regression with interaction terms\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "train_data['High_Volume'] = train_data['High'] * train_data['Volume']\n",
        "test_data['High_Volume'] = test_data['High'] * test_data['Volume']\n",
        "features = ['High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits', 'High_Volume']\n",
        "X_train = train_data[features]\n",
        "y_train = train_data['Open']\n",
        "X_test = test_data[features]\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "test_data['Open'] = model.predict(X_test)\n",
        "output = test_data[['id', 'Open']]\n",
        "output.to_csv('submission2.csv', index=False)\n",
        "print(\"Submission file created: submission.csv\")\n",
        "rmse = mean_squared_error(y_train, train_predictions)\n",
        "r2 = r2_score(y_train, train_predictions)\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"R²: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfRPdlHHf_H9",
        "outputId": "5f0c200f-2c78-4c87-c687-2dd863de5638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created: submission.csv\n",
            "RMSE: 11005542.231182069\n",
            "R²: -0.03427698892655373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: linear regression with polynomial features\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load the training and testing data\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# Define features and target variable\n",
        "features = ['High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
        "X_train = train_data[features]\n",
        "y_train = train_data['Open']\n",
        "X_test = test_data[features]\n",
        "\n",
        "# Create polynomial features\n",
        "poly = PolynomialFeatures(degree=2) # Example: degree 2 polynomial features\n",
        "X_train_poly = poly.fit_transform(X_train)\n",
        "X_test_poly = poly.transform(X_test)\n",
        "\n",
        "# Train a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_poly, y_train)\n",
        "\n",
        "# Make predictions on the training set\n",
        "train_predictions = model.predict(X_train_poly)\n",
        "\n",
        "# Make predictions on the test set\n",
        "test_data['Open'] = model.predict(X_test_poly)\n",
        "\n",
        "# Create submission file\n",
        "output = test_data[['id', 'Open']]\n",
        "output.to_csv('submission_poly.csv', index=False)\n",
        "print(\"Submission file created: submission_poly.csv\")\n",
        "\n",
        "# Evaluate the model\n",
        "rmse = mean_squared_error(y_train, train_predictions) # Calculate RMSE\n",
        "r2 = r2_score(y_train, train_predictions)\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"R²: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFSktmaXQDmU",
        "outputId": "0e86f743-5d7c-4ce0-8b92-94b3c978122d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created: submission_poly.csv\n",
            "RMSE: 1418.9072234858743\n",
            "R²: 0.9998666541766098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Ridge regression\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# Load the training and testing data\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# Define features and target variable\n",
        "features = ['High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
        "X_train = train_data[features]\n",
        "y_train = train_data['Open']\n",
        "X_test = test_data[features]\n",
        "\n",
        "# Create polynomial features (optional)\n",
        "poly = PolynomialFeatures(degree=2) # Example: degree 2 polynomial features\n",
        "X_train_poly = poly.fit_transform(X_train)\n",
        "X_test_poly = poly.transform(X_test)\n",
        "\n",
        "# Train a Ridge Regression model\n",
        "model = Ridge(alpha=1.0) # You can adjust the regularization strength (alpha)\n",
        "model.fit(X_train_poly, y_train) # Use polynomial features if created\n",
        "\n",
        "# Make predictions on the training set\n",
        "train_predictions = model.predict(X_train_poly) # Use polynomial features if created\n",
        "\n",
        "\n",
        "# Make predictions on the test set\n",
        "test_data['Open'] = model.predict(X_test_poly) # Use polynomial features if created\n",
        "\n",
        "# Create submission file\n",
        "output = test_data[['id', 'Open']]\n",
        "output.to_csv('submission_ridge.csv', index=False)\n",
        "print(\"Submission file created: submission_ridge.csv\")\n",
        "\n",
        "# Evaluate the model\n",
        "rmse = mean_squared_error(y_train, train_predictions)\n",
        "r2 = r2_score(y_train, train_predictions)\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"R²: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFMQgn9OSzIq",
        "outputId": "a7e91134-78cc-4aa0-fe1a-eecef6194c82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created: submission_ridge.csv\n",
            "RMSE: 1418.9072234917185\n",
            "R²: 0.9998666541766092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=9.2948e-27): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Robust regression\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import RANSACRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load the training and testing data\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# Define features and target variable\n",
        "features = ['High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
        "X_train = train_data[features]\n",
        "y_train = train_data['Open']\n",
        "X_test = test_data[features]\n",
        "\n",
        "# Robust Regression with RANSAC\n",
        "model = RANSACRegressor(random_state=42)  # You can adjust parameters like min_samples, residual_threshold, etc.\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the training set\n",
        "train_predictions = model.predict(X_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "test_data['Open'] = model.predict(X_test)\n",
        "\n",
        "# Create submission file\n",
        "output = test_data[['id', 'Open']]\n",
        "output.to_csv('submission_ransac.csv', index=False)\n",
        "print(\"Submission file created: submission_ransac.csv\")\n",
        "\n",
        "# Evaluate the model\n",
        "rmse = mean_squared_error(y_train, train_predictions)\n",
        "r2 = r2_score(y_train, train_predictions)\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"R²: {r2}\")"
      ],
      "metadata": {
        "id": "y5K21152T4Ps",
        "outputId": "795ee75e-761a-40ba-e31c-1fbed540286c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created: submission_ransac.csv\n",
            "RMSE: 1478.084567876389\n",
            "R²: 0.9998610928181338\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Lasso regression\n",
        "\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "# Load the training and testing data\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# Define features and target variable\n",
        "features = ['High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
        "X_train = train_data[features]\n",
        "y_train = train_data['Open']\n",
        "X_test = test_data[features]\n",
        "\n",
        "# Train a Lasso Regression model\n",
        "model = Lasso(alpha=1.0)  # You can adjust the regularization strength (alpha)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the training set\n",
        "train_predictions = model.predict(X_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "test_data['Open'] = model.predict(X_test)\n",
        "\n",
        "# Create submission file\n",
        "output = test_data[['id', 'Open']]\n",
        "output.to_csv('submission_lasso.csv', index=False)\n",
        "print(\"Submission file created: submission_lasso.csv\")\n",
        "\n",
        "# Evaluate the model\n",
        "rmse = mean_squared_error(y_train, train_predictions)\n",
        "r2 = r2_score(y_train, train_predictions)\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"R²: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXrNarDEjfbA",
        "outputId": "2fb1a025-d1cc-4e31-9869-735c5f0686af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created: submission_lasso.csv\n",
            "RMSE: 2775.9418905900416\n",
            "R²: 0.9997391230018726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.732e+06, tolerance: 2.094e+06\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Elastic Net Regression\n",
        "\n",
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "# Load the training and testing data\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# Define features and target variable\n",
        "features = ['High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
        "X_train = train_data[features]\n",
        "y_train = train_data['Open']\n",
        "X_test = test_data[features]\n",
        "\n",
        "# Train an Elastic Net Regression model\n",
        "model = ElasticNet(alpha=1.0, l1_ratio=0.5)  # You can adjust alpha and l1_ratio\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the training set\n",
        "train_predictions = model.predict(X_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "test_data['Open'] = model.predict(X_test)\n",
        "\n",
        "# Create submission file\n",
        "output = test_data[['id', 'Open']]\n",
        "output.to_csv('submission_elastic_net.csv', index=False)\n",
        "print(\"Submission file created: submission_elastic_net.csv\")\n",
        "\n",
        "# Evaluate the model\n",
        "rmse = mean_squared_error(y_train, train_predictions)\n",
        "r2 = r2_score(y_train, train_predictions)\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"R²: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MZAFvZ8kBBL",
        "outputId": "5704144d-401a-4eaa-ecc8-e6291e63115f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created: submission_elastic_net.csv\n",
            "RMSE: 2775.722697921389\n",
            "R²: 0.9997391436011243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.732e+06, tolerance: 2.094e+06\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: K-Nearest Neighbours\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "# Load the training and testing data\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# Define features and target variable\n",
        "features = ['High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
        "X_train = train_data[features]\n",
        "y_train = train_data['Open']\n",
        "X_test = test_data[features]\n",
        "\n",
        "# Initialize KNN regressor with k=5 (you can adjust this)\n",
        "model = KNeighborsRegressor(n_neighbors=5)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "train_predictions = model.predict(X_train)\n",
        "test_data['Open'] = model.predict(X_test)\n",
        "\n",
        "# Create submission file\n",
        "output = test_data[['id', 'Open']]\n",
        "output.to_csv('submission_knn.csv', index=False)\n",
        "print(\"Submission file created: submission_knn.csv\")\n",
        "\n",
        "# Evaluate the model\n",
        "rmse = mean_squared_error(y_train, train_predictions)\n",
        "r2 = r2_score(y_train, train_predictions)\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"R²: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gbMo63_le4L",
        "outputId": "616a41ea-dc73-452a-d8b7-b713b0753636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created: submission_knn.csv\n",
            "RMSE: 331366.96412614716\n",
            "R²: 0.9688588514144192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: CatBoost\n",
        "\n",
        "!pip install catboost\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "# Load the training and testing data\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# Define features and target variable\n",
        "features = ['High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
        "X_train = train_data[features]\n",
        "y_train = train_data['Open']\n",
        "X_test = test_data[features]\n",
        "\n",
        "# Initialize CatBoostRegressor\n",
        "model = CatBoostRegressor(iterations=1000,  # Adjust as needed\n",
        "                          learning_rate=0.1, # Adjust as needed\n",
        "                          depth=6,            # Adjust as needed\n",
        "                          loss_function='RMSE',\n",
        "                          random_seed=42,\n",
        "                          verbose=100)       # Adjust verbosity\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "train_predictions = model.predict(X_train)\n",
        "test_data['Open'] = model.predict(X_test)\n",
        "\n",
        "# Create submission file\n",
        "output = test_data[['id', 'Open']]\n",
        "output.to_csv('submission_catboost.csv', index=False)\n",
        "print(\"Submission file created: submission_catboost.csv\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B-Udhv7mref",
        "outputId": "f4889ecb-4a44-4922-fc46-a3790833e7ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.7)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "0:\tlearn: 2952.9030062\ttotal: 2.36ms\tremaining: 2.36s\n",
            "100:\tlearn: 91.8248794\ttotal: 164ms\tremaining: 1.46s\n",
            "200:\tlearn: 71.0242385\ttotal: 313ms\tremaining: 1.24s\n",
            "300:\tlearn: 60.2672647\ttotal: 439ms\tremaining: 1.02s\n",
            "400:\tlearn: 54.1272926\ttotal: 575ms\tremaining: 859ms\n",
            "500:\tlearn: 49.1369460\ttotal: 700ms\tremaining: 698ms\n",
            "600:\tlearn: 45.3479299\ttotal: 827ms\tremaining: 549ms\n",
            "700:\tlearn: 42.3650610\ttotal: 950ms\tremaining: 405ms\n",
            "800:\tlearn: 39.6254741\ttotal: 1.09s\tremaining: 270ms\n",
            "900:\tlearn: 37.2016169\ttotal: 1.23s\tremaining: 135ms\n",
            "999:\tlearn: 35.1250327\ttotal: 1.35s\tremaining: 0us\n",
            "Submission file created: submission_catboost.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Support Vector Regression (SVR) with full code\n",
        "\n",
        "# SVM algorithm\n",
        "from sklearn.svm import SVR # Add this import statement to import the SVR class\n",
        "\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "features = ['High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
        "X_train = train_data[features]\n",
        "y_train = train_data['Open']\n",
        "X_test = test_data[features]\n",
        "model = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1) #Example parameters, tune these\n",
        "model.fit(X_train, y_train)\n",
        "train_predictions = model.predict(X_train)\n",
        "test_data['Open'] = model.predict(X_test)\n",
        "output = test_data[['id', 'Open']]\n",
        "output.to_csv('submission_svr_tuned.csv', index=False)\n",
        "print(\"Submission file created: submission_svr_tuned.csv\")\n",
        "rmse = mean_squared_error(y_train, train_predictions)\n",
        "r2 = r2_score(y_train, train_predictions)\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"R²: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnzcfTYwnhVj",
        "outputId": "2a37ee78-0a54-4025-dbab-57319b822d0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created: submission_svr_tuned.csv\n",
            "RMSE: 10788603.239690753\n",
            "R²: -0.013889533025955192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Multi-layer Perceptron (MLP)\n",
        "\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "# Load the training and testing data\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# Define features and target variable\n",
        "features = ['High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
        "X_train = train_data[features]\n",
        "y_train = train_data['Open']\n",
        "X_test = test_data[features]\n",
        "\n",
        "# Initialize MLPRegressor\n",
        "model = MLPRegressor(hidden_layer_sizes=(100, 50), # Example architecture, adjust as needed\n",
        "                    activation='relu',            # Activation function\n",
        "                    solver='adam',                # Solver for weight optimization\n",
        "                    alpha=0.0001,                 # L2 regularization\n",
        "                    batch_size='auto',\n",
        "                    learning_rate='constant',\n",
        "                    learning_rate_init=0.001,\n",
        "                    max_iter=200,                 # Maximum number of iterations\n",
        "                    random_state=42,\n",
        "                    verbose=True)\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Make predictions\n",
        "train_predictions = model.predict(X_train)\n",
        "test_data['Open'] = model.predict(X_test)\n",
        "\n",
        "# Create submission file\n",
        "output = test_data[['id', 'Open']]\n",
        "output.to_csv('submission_mlp.csv', index=False)\n",
        "print(\"Submission file created: submission_mlp.csv\")\n",
        "\n",
        "# Evaluate the model\n",
        "rmse = mean_squared_error(y_train, train_predictions)\n",
        "r2 = r2_score(y_train, train_predictions)\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"R²: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWor9w9loJYo",
        "outputId": "738e01c4-6a67-4cfb-b405-e301e89c852c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 32940504.11721972\n",
            "Iteration 2, loss = 17776330.30035064\n",
            "Iteration 3, loss = 10919130.16866758\n",
            "Iteration 4, loss = 4129077.58242200\n",
            "Iteration 5, loss = 828332.19372229\n",
            "Iteration 6, loss = 140136.42798752\n",
            "Iteration 7, loss = 66709.19157677\n",
            "Iteration 8, loss = 21967.91086864\n",
            "Iteration 9, loss = 13324.71089899\n",
            "Iteration 10, loss = 8010.33382871\n",
            "Iteration 11, loss = 5609.60348224\n",
            "Iteration 12, loss = 4363.85631319\n",
            "Iteration 13, loss = 4407.05959778\n",
            "Iteration 14, loss = 3639.21057096\n",
            "Iteration 15, loss = 3599.22811853\n",
            "Iteration 16, loss = 3937.93603190\n",
            "Iteration 17, loss = 4453.74833465\n",
            "Iteration 18, loss = 3991.94056050\n",
            "Iteration 19, loss = 3256.07731946\n",
            "Iteration 20, loss = 2996.10675520\n",
            "Iteration 21, loss = 3389.81824991\n",
            "Iteration 22, loss = 5278.89478066\n",
            "Iteration 23, loss = 9449.92561776\n",
            "Iteration 24, loss = 7255.46229255\n",
            "Iteration 25, loss = 4774.04093169\n",
            "Iteration 26, loss = 4066.53228099\n",
            "Iteration 27, loss = 3878.93435145\n",
            "Iteration 28, loss = 3468.77696269\n",
            "Iteration 29, loss = 3066.74517824\n",
            "Iteration 30, loss = 3221.36465151\n",
            "Iteration 31, loss = 3569.73659567\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Submission file created: submission_mlp.csv\n",
            "RMSE: 9347.96215046967\n",
            "R²: 0.9991214987919275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Recurrent Neural Networks\n",
        "\n",
        "# Load the training and testing data\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# Define features and target variable\n",
        "features = ['High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
        "X_train = train_data[features]\n",
        "y_train = train_data['Open']\n",
        "X_test = test_data[features]\n",
        "\n",
        "#Scaling data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "#Reshape for RNN\n",
        "import numpy as np\n",
        "X_train_reshaped = np.reshape(X_train_scaled, (X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
        "X_test_reshaped = np.reshape(X_test_scaled, (X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
        "\n",
        "# Import necessary libraries\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "\n",
        "# Build the RNN model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dense(1)) # Output layer with 1 neuron for regression\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32)\n",
        "\n",
        "# Make predictions\n",
        "train_predictions = model.predict(X_train_reshaped)\n",
        "y_pred = model.predict(X_test_reshaped)\n",
        "\n",
        "# Inverse transform to get actual values\n",
        "# Reshape y_pred to have the original number of features (6 in this case)\n",
        "y_pred_reshaped = np.repeat(y_pred, X_train.shape[1], axis=1)\n",
        "test_data['Open'] = scaler.inverse_transform(y_pred_reshaped)[:, 0] # Get the first column after inverse transform\n",
        "\n",
        "# Create submission file\n",
        "output = test_data[['id', 'Open']]\n",
        "output.to_csv('submission_rnn.csv', index=False)\n",
        "print(\"Submission file created: submission_rnn.csv\")\n",
        "\n",
        "# Evaluate the model\n",
        "rmse = mean_squared_error(y_train, train_predictions)\n",
        "r2 = r2_score(y_train, train_predictions)\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"R²: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdReRIh4oaDV",
        "outputId": "e7e4c6e3-a69f-4a06-81ac-e9d9130f37a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 145428304.0000\n",
            "Epoch 2/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 147021424.0000\n",
            "Epoch 3/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 143465696.0000\n",
            "Epoch 4/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 145424240.0000\n",
            "Epoch 5/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 141430144.0000\n",
            "Epoch 6/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 143737136.0000\n",
            "Epoch 7/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 145703200.0000\n",
            "Epoch 8/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 140414608.0000\n",
            "Epoch 9/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 144233120.0000\n",
            "Epoch 10/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 143350672.0000\n",
            "Epoch 11/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 145097808.0000\n",
            "Epoch 12/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 143443072.0000\n",
            "Epoch 13/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 144400816.0000\n",
            "Epoch 14/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 144742016.0000\n",
            "Epoch 15/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 145230592.0000\n",
            "Epoch 16/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 142249488.0000\n",
            "Epoch 17/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 143819472.0000\n",
            "Epoch 18/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 142689680.0000\n",
            "Epoch 19/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 145445792.0000\n",
            "Epoch 20/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 145248272.0000\n",
            "Epoch 21/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 142007712.0000\n",
            "Epoch 22/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 144108576.0000\n",
            "Epoch 23/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 144670464.0000\n",
            "Epoch 24/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 146344848.0000\n",
            "Epoch 25/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 145403184.0000\n",
            "Epoch 26/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 144086512.0000\n",
            "Epoch 27/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 142724672.0000\n",
            "Epoch 28/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 141828752.0000\n",
            "Epoch 29/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 141560640.0000\n",
            "Epoch 30/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 141732240.0000\n",
            "Epoch 31/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 142190720.0000\n",
            "Epoch 32/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 139595984.0000\n",
            "Epoch 33/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 139918608.0000\n",
            "Epoch 34/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 141836784.0000\n",
            "Epoch 35/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 142717344.0000\n",
            "Epoch 36/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 143207584.0000\n",
            "Epoch 37/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 141917328.0000\n",
            "Epoch 38/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 146658176.0000\n",
            "Epoch 39/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 141050528.0000\n",
            "Epoch 40/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 145460656.0000\n",
            "Epoch 41/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 139385040.0000\n",
            "Epoch 42/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 142635520.0000\n",
            "Epoch 43/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 139998976.0000\n",
            "Epoch 44/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 141475104.0000\n",
            "Epoch 45/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 140790544.0000\n",
            "Epoch 46/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 140492464.0000\n",
            "Epoch 47/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 141555360.0000\n",
            "Epoch 48/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 138611232.0000\n",
            "Epoch 49/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 142694064.0000\n",
            "Epoch 50/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 142552064.0000\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Submission file created: submission_rnn.csv\n",
            "RMSE: 141607163.39145732\n",
            "R²: -12.307934083245629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: \"Implement early stopping during the training of a neural network. Monitor the validation loss and stop training if it doesn't improve for 5 consecutive epochs.\" give full code\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# ... (your existing code for data loading and preprocessing) ...\n",
        "\n",
        "# Define the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))  # Input layer\n",
        "model.add(Dense(32, activation='relu'))  # Hidden layer\n",
        "model.add(Dense(1))  # Output layer\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Implement early stopping\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    patience=5,          # Number of epochs with no improvement after which training will be stopped\n",
        "    restore_best_weights=True # Restore model weights from the epoch with the best validation loss\n",
        ")\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100,  # Maximum number of epochs (can be higher, early stopping will prevent overfitting)\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,  # Use 20% of the training data for validation\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "train_predictions = model.predict(X_train)\n",
        "rmse = np.sqrt(mean_squared_error(y_train, train_predictions))\n",
        "print(f\"RMSE on training data: {rmse}\")\n",
        "\n",
        "test_data['Open'] = model.predict(X_test)\n",
        "output = test_data[['id', 'Open']]\n",
        "output.to_csv('submission_nn_early_stopping.csv', index=False)\n",
        "print(\"Submission file created: submission_nn_early_stopping.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjwwpRcCtKv3",
        "outputId": "7446b4b3-3557-4c97-809a-fa0e2e448480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 3624370432.0000 - val_loss: 39657896.0000\n",
            "Epoch 2/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 43899328.0000 - val_loss: 23842362.0000\n",
            "Epoch 3/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18952732.0000 - val_loss: 6779954.5000\n",
            "Epoch 4/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3763922.0000 - val_loss: 488777.5625\n",
            "Epoch 5/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 292133.5000 - val_loss: 34174.6719\n",
            "Epoch 6/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32825.2578 - val_loss: 23736.6777\n",
            "Epoch 7/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18850.0020 - val_loss: 23267.2344\n",
            "Epoch 8/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21817.1016 - val_loss: 17103.9531\n",
            "Epoch 9/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12564.3760 - val_loss: 17689.8359\n",
            "Epoch 10/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19518.1348 - val_loss: 16728.1816\n",
            "Epoch 11/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23574.5020 - val_loss: 15543.5459\n",
            "Epoch 12/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13880.0801 - val_loss: 30286.5469\n",
            "Epoch 13/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19890.4531 - val_loss: 15532.1045\n",
            "Epoch 14/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17690.8105 - val_loss: 25731.0430\n",
            "Epoch 15/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17310.2227 - val_loss: 17451.6660\n",
            "Epoch 16/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 13495.2705 - val_loss: 22013.4199\n",
            "Epoch 17/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14109.8506 - val_loss: 15807.6094\n",
            "Epoch 18/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14592.5156 - val_loss: 23016.1562\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "RMSE on training data: 123.12091602876991\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
            "Submission file created: submission_nn_early_stopping.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: \"Engineer new features for the linear regression model by:\n",
        "#    - Creating interaction terms between 'feature1' and 'feature2'.\n",
        "#    - Applying polynomial transformations (degree 2) to 'feature3'.\n",
        "#    - Encoding the categorical variable 'feature4' using one-hot encoding.\"\n",
        "\n",
        "# ... (your existing code) ...\n",
        "\n",
        "# Load the training and testing data\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# Feature Engineering\n",
        "# 1. Interaction term\n",
        "train_data['interaction'] = train_data['High'] * train_data['Low']\n",
        "test_data['interaction'] = test_data['High'] * test_data['Low']\n",
        "\n",
        "# 2. Polynomial features\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "# Remove the slicing to assign both polynomial features\n",
        "train_data[['feature3_poly1', 'feature3_poly2']] = poly.fit_transform(train_data[['Close']])\n",
        "test_data[['feature3_poly1', 'feature3_poly2']] = poly.transform(test_data[['Close']])\n",
        "\n",
        "# 3. One-hot encoding (assuming 'feature4' is a categorical column)\n",
        "# Replace 'feature4' with the actual name of your categorical column\n",
        "train_data = pd.get_dummies(train_data, columns=['Dividends'], prefix='Dividends', drop_first = True)\n",
        "test_data = pd.get_dummies(test_data, columns=['Dividends'], prefix='Dividends', drop_first = True)\n",
        "\n",
        "\n",
        "# Redefine features to include engineered features\n",
        "features = ['High', 'Low', 'Close', 'Volume', 'Stock Splits', 'interaction', 'feature3_poly1', 'feature3_poly2']\n",
        "features = features + list(train_data.filter(regex='Dividends').columns) # Add one-hot encoded columns\n",
        "X_train = train_data[features]\n",
        "y_train = train_data['Open']\n",
        "X_test = test_data[features]\n",
        "\n",
        "# Train the model (using Linear Regression as an example)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "train_predictions = model.predict(X_train)\n",
        "test_data['Open'] = model.predict(X_test)\n",
        "\n",
        "# Create submission file\n",
        "output = test_data[['id', 'Open']]\n",
        "output.to_csv('submission_engineered.csv', index=False)\n",
        "print(\"Submission file created: submission_engineered.csv\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0nxdBQAuQHX",
        "outputId": "4298165e-b5b7-4a9a-de42-09d65ca62353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created: submission_engineered.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: \"Scale the numerical features using StandardScaler before training the linear regression model to improve its performance.\"\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the training and testing data\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# Define features and target variable\n",
        "features = ['High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
        "X_train = train_data[features]\n",
        "y_train = train_data['Open']\n",
        "X_test = test_data[features]\n",
        "\n",
        "# Scale numerical features using StandardScaler\n",
        "numerical_features = ['High', 'Low', 'Close', 'Volume']\n",
        "scaler = StandardScaler()\n",
        "X_train[numerical_features] = scaler.fit_transform(X_train[numerical_features])\n",
        "X_test[numerical_features] = scaler.transform(X_test[numerical_features])\n",
        "\n",
        "# Train a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "train_predictions = model.predict(X_train)\n",
        "test_data['Open'] = model.predict(X_test)\n",
        "\n",
        "# Create submission file\n",
        "output = test_data[['id', 'Open']]\n",
        "output.to_csv('submission_scaled.csv', index=False)\n",
        "print(\"Submission file created: submission_scaled.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdT2xNVhvCop",
        "outputId": "68d74260-5ce9-4ad1-8c17-52758f011c91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created: submission_scaled.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-db88a9c8d136>:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_train[numerical_features] = scaler.fit_transform(X_train[numerical_features])\n",
            "<ipython-input-23-db88a9c8d136>:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_test[numerical_features] = scaler.transform(X_test[numerical_features])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: \"Evaluate the linear regression model using 5-fold cross-validation to get a more reliable estimate of its performance.\" Use train set and get predictions\\\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Load the training and testing data (assuming you have already loaded them)\n",
        "# ... (your existing code for data loading and preprocessing) ...\n",
        "\n",
        "# Define features and target variable\n",
        "features = ['High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
        "X_train = train_data[features]\n",
        "y_train = train_data['Open']\n",
        "\n",
        "\n",
        "# Initialize the model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "n_splits = 5\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42) # Use KFold for cross-validation\n",
        "\n",
        "rmse_scores = []\n",
        "predictions = np.zeros_like(y_train, dtype=float) # Initialize an array to store predictions\n",
        "\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(kf.split(X_train)):\n",
        "    print(f\"Fold {fold+1}\")\n",
        "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
        "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "\n",
        "    # Fit the model on the training fold\n",
        "    model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions on the validation fold\n",
        "    val_predictions = model.predict(X_val_fold)\n",
        "    predictions[val_index] = val_predictions\n",
        "\n",
        "    # Evaluate the model on the validation fold\n",
        "    rmse = np.sqrt(mean_squared_error(y_val_fold, val_predictions))\n",
        "    rmse_scores.append(rmse)\n",
        "    print(f\"RMSE for fold {fold+1}: {rmse}\")\n",
        "\n",
        "# Calculate the average RMSE across all folds\n",
        "avg_rmse = np.mean(rmse_scores)\n",
        "print(f\"\\nAverage RMSE across all folds: {avg_rmse}\")\n",
        "\n",
        "# Evaluate the model on the entire training set using the cross-validated predictions\n",
        "overall_rmse = np.sqrt(mean_squared_error(y_train, predictions))\n",
        "print(f\"Overall RMSE on training set using CV predictions: {overall_rmse}\")\n",
        "\n",
        "# Now you can use the trained model to make predictions on the test set.\n",
        "\n",
        "test_data['Open'] = model.predict(X_test)\n",
        "output = test_data[['id', 'Open']]\n",
        "output.to_csv('submission_cv.csv', index=False)\n",
        "print(\"Submission file created: submission_cv.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dERzhyMTvnqh",
        "outputId": "6d30969b-0551-48c6-b03f-58839cba47b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1\n",
            "RMSE for fold 1: 40.56053403546554\n",
            "Fold 2\n",
            "RMSE for fold 2: 36.44085067993343\n",
            "Fold 3\n",
            "RMSE for fold 3: 36.96190147414126\n",
            "Fold 4\n",
            "RMSE for fold 4: 36.996981447135234\n",
            "Fold 5\n",
            "RMSE for fold 5: 41.846127993662144\n",
            "\n",
            "Average RMSE across all folds: 38.561279126067525\n",
            "Overall RMSE on training set using CV predictions: 38.62331852455698\n",
            "Submission file created: submission_cv.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "if tf.test.gpu_device_name():\n",
        "    print(\"GPU in use:\", tf.test.gpu_device_name())\n",
        "else:\n",
        "    print(\"Using CPU\")\n",
        "!lscpu | grep 'Model name'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAjxggSW_ngt",
        "outputId": "ff1b31c1-a32b-402c-ce9a-0890f01fbb6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.17.1\n",
            "Using CPU\n",
            "Model name:                           Intel(R) Xeon(R) CPU @ 2.20GHz\n"
          ]
        }
      ]
    }
  ]
}